{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functions import main_cleaning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "df_raw = pd.read_csv(\"dielectron.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Iván\\Documentos\\Clase\\Informatica\\Beca IronHack\\Temario\\PROYECTOS\\Proyecto_Final_IronHack\\functions.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"is_same_charge\"] = df[\"Q1\"] == df[\"Q2\"]\n",
      "e:\\Iván\\Documentos\\Clase\\Informatica\\Beca IronHack\\Temario\\PROYECTOS\\Proyecto_Final_IronHack\\functions.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"is_outlier\"] = False\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = main_cleaning(df_raw)\n",
    "df_cleaned.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event has one value repeated. We have 2 options: \n",
    "# We can either drop it or create an ID for Event. We will do the last.\n",
    "\n",
    "df_cleaned[df_cleaned[\"Event\"] == 418006834]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Run\" table\n",
    "\n",
    "df_run = df_cleaned[[\"Run\"]].drop_duplicates().copy()\n",
    "\n",
    "df_run[\"date_run\"] = pd.NaT\n",
    "\n",
    "df_run.rename(columns={\"Run\": \"run_num\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Particle A\" table\n",
    "\n",
    "df_particle_a = df_cleaned[[\"E1\", \"px1\", \"py1\", \"pz1\", \"pt1\", \"eta1\", \"phi1\", \"Q1\"]].copy()\n",
    "\n",
    "df_particle_a.rename(columns={\"E1\": \"energy\", \"px1\": \"px\", \"py1\": \"py\", \"pz1\": \"pz\", \"pt1\": \"pt\", \"eta1\": \"eta\", \"phi1\": \"phi\", \"Q1\": \"charge\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Particle B\" table\n",
    "\n",
    "df_particle_b = df_cleaned[[\"E2\", \"px2\", \"py2\", \"pz2\", \"pt2\", \"eta2\", \"phi2\", \"Q2\"]].copy()\n",
    "\n",
    "df_particle_b.rename(columns={\"E2\": \"energy\", \"px2\": \"px\", \"py2\": \"py\", \"pz2\": \"pz\", \"pt2\": \"pt\", \"eta2\": \"eta\", \"phi2\": \"phi\", \"Q2\": \"charge\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functions import import_to_sql\n",
    "\n",
    "# import_to_sql(df_run, \"run\")\n",
    "# import_to_sql(df_particle_a, \"particle_a\")\n",
    "# import_to_sql(df_particle_b, \"particle_b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID for particles\n",
    "\n",
    "from functions import make_query\n",
    "\n",
    "id_partA_query = \"SELECT id_part FROM particle_a\"\n",
    "id_partA = make_query(id_partA_query)\n",
    "\n",
    "id_partB_query = \"SELECT id_part FROM particle_b\"\n",
    "id_partB = make_query(id_partB_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event table\n",
    "\n",
    "df_event = df_cleaned[[\"Event\", \"Run\", \"M\"]].copy()\n",
    "\n",
    "df_event[\"id_partA\"] = id_partA\n",
    "df_event[\"id_partB\"] = id_partB\n",
    "\n",
    "df_event.rename(columns={\"Event\": \"event_num\", \"Run\": \"run_num\", \"M\": \"invariant_mass\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import_to_sql(df_event, \"event\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los resultados de MSE, MAE y R2 para KNN sin normalizar eran: \n",
    "MAE: 17.717622715597013  \n",
    "MSE: 12.581512831873468   \n",
    "R2: 0.507506217561434  \n",
    "### So I will normalize/standarize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df_cleaned.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_ml[[\"Run\", \"px1\", \"py1\", \"pz1\", \"px2\", \"py2\", \"pz2\", \"is_same_charge\", \"is_outlier\"]]\n",
    "target = df_ml[[\"M\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "normalizer = MinMaxScaler()\n",
    "\n",
    "X_train_norm= normalizer.fit_transform(X_train)        \n",
    "\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = pd.DataFrame(X_train_norm, columns = X_train.columns)   \n",
    "X_test_norm = pd.DataFrame(X_test_norm, columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I will try 5 different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "  'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "  'Linear Regression': LinearRegression(),\n",
    "  'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "  'Random Forest': RandomForestRegressor(random_state=42, n_estimators=100),\n",
    "  'SVR': SVR(),\n",
    "}   \n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "  # Train the model\n",
    "    model.fit(X_train_norm, y_train)\n",
    "  \n",
    "  # Make predictions\n",
    "    y_pred_norm = model.predict(X_test_norm)\n",
    "\n",
    "    mae_standardized = mean_absolute_error(y_test, y_pred_norm)\n",
    "    mse_standardized = root_mean_squared_error(y_test, y_pred_norm)\n",
    "    r2_standardized = r2_score(y_test, y_pred_norm)\n",
    "  \n",
    "  # Store results\n",
    "    results[name] = {\n",
    "        'mae' : mae_standardized,\n",
    "        'mse' : mse_standardized,\n",
    "        'R2' : r2_standardized\n",
    "  }\n",
    "\n",
    "# Print results\n",
    "for name, result in results.items():\n",
    "  print(f\"\\n{name}:\")\n",
    "  print(f\"Mean Absolute Error: {result['mae']}\")\n",
    "  print(f\"Root Mean Squared Error: {result['mse']}\")\n",
    "  print(f\"R2: {result['R2']}\")\n",
    "\n",
    "# Compare R2_value\n",
    "r2_values = {name: result['R2'] for name, result in results.items()}\n",
    "best_model = max(r2_values, key=r2_values.get)\n",
    "\n",
    "print(\"\\nModel Accuracy Comparison:\")\n",
    "for name, accuracy in r2_values.items():\n",
    "  print(f\"{name}: {accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nBest performing model: {best_model} with accuracy {r2_values[best_model]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)        \n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns = X_train.columns)   \n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "  'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "  'Linear Regression': LinearRegression(),\n",
    "  'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "  'Random Forest': RandomForestRegressor(random_state=42, n_estimators=100),\n",
    "  'SVR': SVR(),\n",
    "}   \n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "  # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "  \n",
    "  # Make predictions\n",
    "    y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "    mae_standardized = mean_absolute_error(y_test, y_pred_scaled)\n",
    "    mse_standardized = root_mean_squared_error(y_test, y_pred_scaled)\n",
    "    r2_standardized = r2_score(y_test, y_pred_scaled)\n",
    "  \n",
    "  # Store results\n",
    "    results[name] = {\n",
    "        'mae' : mae_standardized,\n",
    "        'mse' : mse_standardized,\n",
    "        'R2' : r2_standardized\n",
    "  }\n",
    "\n",
    "# Print results\n",
    "for name, result in results.items():\n",
    "  print(f\"\\n{name}:\")\n",
    "  print(f\"Mean Absolute Error: {result['mae']}\")\n",
    "  print(f\"Root Mean Squared Error: {result['mse']}\")\n",
    "  print(f\"R2: {result['R2']}\")\n",
    "\n",
    "# Compare R2_value\n",
    "r2_values = {name: result['R2'] for name, result in results.items()}\n",
    "best_model = max(r2_values, key=r2_values.get)\n",
    "\n",
    "print(\"\\nModel Accuracy Comparison:\")\n",
    "for name, accuracy in r2_values.items():\n",
    "  print(f\"{name}: {accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nBest performing model: {best_model} with accuracy {r2_values[best_model]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We take Standarized Random Forest as the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we are going to try RF removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lower = df_ml[[\"Run\", \"pz1\", \"pz2\", \"is_same_charge\", \"is_outlier\"]]\n",
    "target_lower = df_ml[[\"M\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_lower, target_lower, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_lower = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_lower.fit_transform(X_train)        \n",
    "\n",
    "X_test_scaled = scaler_lower.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns = X_train.columns)   \n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_lower = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "\n",
    "rf_lower.fit(X_train_scaled, y_train)\n",
    "  \n",
    "y_pred_lower_scaled = rf_lower.predict(X_test_scaled)\n",
    "\n",
    "mae_standardized = mean_absolute_error(y_test, y_pred_lower_scaled)\n",
    "mse_standardized = root_mean_squared_error(y_test, y_pred_lower_scaled)\n",
    "r2_standardized = r2_score(y_test, y_pred_lower_scaled)\n",
    "\n",
    "mae_standardized, mse_standardized, r2_standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo -> (2.3447513779118077, 3.9098505538185626, 0.9760166321541155)\n",
    "\n",
    "Sin py -> (5.030465963967166, 8.80652660636964, 0.8783256160020667)\n",
    "\n",
    "Sin py ni pz -> (16.016459623359527, 21.49041157214318, 0.2754317177361222)\n",
    "\n",
    "Sin px ni py -> (9.648483653205867, 15.70953893783305, 0.6128165981972764)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_scaled = scaler_lower.transform(features_lower)\n",
    "\n",
    "y_pred_lower_real = rf_lower.predict(features_scaled)\n",
    "\n",
    "\n",
    "mae_standardized = mean_absolute_error(target_lower, y_pred_lower_real)\n",
    "mse_standardized = root_mean_squared_error(target_lower, y_pred_lower_real)\n",
    "r2_standardized = r2_score(target_lower, y_pred_lower_real)\n",
    "\n",
    "mae_standardized, mse_standardized, r2_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml[\"pred\"] = y_pred_lower_real\n",
    "\n",
    "df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Aplicamos la validación cruzada en el conjunto de entrenamiento\n",
    "scores = cross_val_score(rf_lower, X_train_lower_scaled, y_train_lower, cv=5, scoring='r2')\n",
    "\n",
    "print(\"Cross-validated R2 scores:\", scores)\n",
    "print(\"Mean cross-validated R2:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying with Random Forest and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Define hyperparameter space for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 300, 500],  # Número de árboles en el bosque\n",
    "    'max_depth': [None, 10, 30, 50],        # Máxima profundidad de cada árbol\n",
    "    #'min_samples_split': [2, 5, 10],                # Número mínimo de muestras requeridas para dividir un nodo\n",
    "    'min_samples_leaf': [1, 2, 4],                  # Número mínimo de muestras requeridas para estar en una hoja\n",
    "    #'max_features': ['auto', 'sqrt',],       # Número de características a considerar para la mejor división\n",
    "    #'bootstrap': [True, False],                     # Método para seleccionar muestras para entrenar cada árbol\n",
    "    #'criterion': ['absolute_error', 'friedman_mse', 'poisson', 'squared_error'],               # Función para medir la calidad de una división\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize base XGBoost model\n",
    "rf_regressor = RandomForestRegressor()\n",
    "\n",
    "# Set up KFold cross-validation\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Configure GridSearchCV for RF\n",
    "grid_search_rf = GridSearchCV(rf_regressor, param_grid_rf, cv=kfold, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Train GridSearchCV with XGBoost\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Extract the optimal XGBoost model\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "# Predict using the optimal model\n",
    "y_pred_train_best_rf = best_rf.predict(X_train)\n",
    "y_pred_test_best_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Cross-validation scores for XGBoost using best_xgb\n",
    "mse_scores_rf = cross_val_score(best_rf, X_train, y_train, cv=kfold, scoring=mse_scorer)\n",
    "r2_scores_rf = cross_val_score(best_rf, X_train, y_train, cv=kfold, scoring=r2_scorer)\n",
    "mae_scores_rf = cross_val_score(best_rf, X_train, y_train, cv=kfold, scoring=mae_scorer)\n",
    "\n",
    "# Compile results into a DataFrame for XGBoost with Grid Search\n",
    "evaluation_metrics_xgb = {\n",
    "    'Model': ['RandomForest (Grid Search)'],\n",
    "    'Avg_MSE_CV': [np.mean(mse_scores_rf)],\n",
    "    'Std_MSE_CV': [np.std(mse_scores_rf)],\n",
    "    'Avg_R2_CV': [np.mean(r2_scores_rf)],\n",
    "    'Std_R2_CV': [np.std(r2_scores_rf)],\n",
    "    'Avg_MAE_CV': [np.mean(mae_scores_rf)],\n",
    "    'Std_MAE_CV': [np.std(mae_scores_rf)],\n",
    "    'MSE_Train': [root_mean_squared_error(y_train, y_pred_train_best_rf)],\n",
    "    'R2_Train': [r2_score(y_train, y_pred_train_best_rf)],\n",
    "    'MAE_Train': [mean_absolute_error(y_train, y_pred_train_best_rf)],\n",
    "    'MSE_Test': [root_mean_squared_error(y_test, y_pred_test_best_rf)],\n",
    "    'R2_Test': [r2_score(y_test, y_pred_test_best_rf)],\n",
    "    'MAE_Test': [mean_absolute_error(y_test, y_pred_test_best_rf)]\n",
    "}\n",
    "\n",
    "rf_results_df = pd.DataFrame(evaluation_metrics_xgb)\n",
    "\n",
    "# # Append results to the existing DataFrame\n",
    "# results_df = pd.concat([results_df, xgb_results_df], ignore_index=True)\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin px -> Mean cross-validated R2: 0.8715048380715927\n",
    "\n",
    "Sin px ni py -> Mean cross-validated R2: 0.6095551354410731"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A new model: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "xg_model = xgb.XGBRegressor()\n",
    "\n",
    "grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],            # Número de árboles\n",
    "    'max_depth': [3, 5, 7, 9, 11],                        # Profundidad máxima de los árboles\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],        # Tasa de aprendizaje\n",
    "    'subsample': [0.6, 0.8, 1.0],                         # Proporción de muestras utilizadas para entrenar\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],                 # Proporción de características utilizadas para entrenar\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],                          # Reducción de pérdida requerida para hacer una partición adicional\n",
    "    'reg_alpha': [0, 0.1, 1, 10],                         # Regularización L1\n",
    "    'reg_lambda': [0, 0.1, 1, 10]                        # Regularización L2\n",
    "}\n",
    "\n",
    "\n",
    "xg_model_randomized_search = RandomizedSearchCV(estimator = xg_model, param_distributions = grid, n_iter = 10, cv = 5, n_jobs = -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.099255470977, 14.89928796896824, 0.6517261382987032)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_model_randomized_search.fit(X_train_scaled, y_train)\n",
    "  \n",
    "y_pred_scaled = xg_model_randomized_search.predict(X_test_scaled)\n",
    "\n",
    "mae_standardized = mean_absolute_error(y_test, y_pred_scaled)\n",
    "mse_standardized = root_mean_squared_error(y_test, y_pred_scaled)\n",
    "r2_standardized = r2_score(y_test, y_pred_scaled)\n",
    "\n",
    "mae_standardized, mse_standardized, r2_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated R2 scores: [0.65769514 0.6539168  0.65243117 0.64477293 0.63621046]\n",
      "Mean cross-validated R2: 0.6490053011901388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Aplicamos la validación cruzada en el conjunto de entrenamiento\n",
    "scores = cross_val_score(xg_model_randomized_search, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "\n",
    "print(\"Cross-validated R2 scores:\", scores)\n",
    "print(\"Mean cross-validated R2:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
