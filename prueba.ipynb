{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functions import main_cleaning\n",
    "\n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "df_raw = pd.read_csv(\"dielectron.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Iván\\Documentos\\Clase\\Informatica\\Beca IronHack\\Temario\\PROYECTOS\\Proyecto_final_1710\\functions.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"is_same_charge\"] = df[\"Q1\"] == df[\"Q2\"]\n",
      "e:\\Iván\\Documentos\\Clase\\Informatica\\Beca IronHack\\Temario\\PROYECTOS\\Proyecto_final_1710\\functions.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"is_outlier\"] = False\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = main_cleaning(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.dropna()         # Solo lo hago en el df_cleaned de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cleaned.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results sin normnalizar -> (17.717622715597013, 12.581512831873468, 0.507506217561434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_cleaned[[\"Run\", \"px1\", \"py1\", \"pz1\", \"phi1\", \"eta1\", \"px2\", \"py2\", \"pz2\",\"phi2\", \"eta2\", \"is_same_charge\", \"is_outlier\"]]\n",
    "target = df_cleaned[[\"M\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "normalizer = MinMaxScaler()\n",
    "\n",
    "X_train_norm= normalizer.fit_transform(X_train)        \n",
    "\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = pd.DataFrame(X_train_norm, columns = X_train.columns)   \n",
    "X_test_norm = pd.DataFrame(X_test_norm, columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error, make_scorer\n",
    "\n",
    "\n",
    "mse_scorer = make_scorer(root_mean_squared_error)\n",
    "r2_scorer = make_scorer(r2_score)\n",
    "mae_scorer = make_scorer(mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Define hyperparameter space for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200, 300, 400, 500],  # Número de árboles en el bosque\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],        # Máxima profundidad de cada árbol\n",
    "    'min_samples_split': [2, 5, 10],                # Número mínimo de muestras requeridas para dividir un nodo\n",
    "    'min_samples_leaf': [1, 2, 4],                  # Número mínimo de muestras requeridas para estar en una hoja\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],       # Número de características a considerar para la mejor división\n",
    "    'bootstrap': [True, False],                     # Método para seleccionar muestras para entrenar cada árbol\n",
    "    'criterion': ['absolute_error', 'friedman_mse', 'poisson', 'squared_error'],               # Función para medir la calidad de una división\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize base XGBoost model\n",
    "rf_regressor = RandomForestRegressor()\n",
    "\n",
    "# Set up KFold cross-validation\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Configure GridSearchCV for RF\n",
    "grid_search_rf = GridSearchCV(rf_regressor, param_grid_rf, cv=kfold, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Train GridSearchCV with XGBoost\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Extract the optimal XGBoost model\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "# Predict using the optimal model\n",
    "y_pred_train_best_rf = best_rf.predict(X_train)\n",
    "y_pred_test_best_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Cross-validation scores for XGBoost using best_xgb\n",
    "mse_scores_rf = cross_val_score(best_rf, X_train, y_train, cv=kfold, scoring=mse_scorer)\n",
    "r2_scores_rf = cross_val_score(best_rf, X_train, y_train, cv=kfold, scoring=r2_scorer)\n",
    "mae_scores_rf = cross_val_score(best_rf, X_train, y_train, cv=kfold, scoring=mae_scorer)\n",
    "\n",
    "# Compile results into a DataFrame for XGBoost with Grid Search\n",
    "evaluation_metrics_xgb = {\n",
    "    'Model': ['RandomForest (Grid Search)'],\n",
    "    'Avg_MSE_CV': [np.mean(mse_scores_rf)],\n",
    "    'Std_MSE_CV': [np.std(mse_scores_rf)],\n",
    "    'Avg_R2_CV': [np.mean(r2_scores_rf)],\n",
    "    'Std_R2_CV': [np.std(r2_scores_rf)],\n",
    "    'Avg_MAE_CV': [np.mean(mae_scores_rf)],\n",
    "    'Std_MAE_CV': [np.std(mae_scores_rf)],\n",
    "    'MSE_Train': [root_mean_squared_error(y_train, y_pred_train_best_rf)],\n",
    "    'R2_Train': [r2_score(y_train, y_pred_train_best_rf)],\n",
    "    'MAE_Train': [mean_absolute_error(y_train, y_pred_train_best_rf)],\n",
    "    'MSE_Test': [root_mean_squared_error(y_test, y_pred_test_best_rf)],\n",
    "    'R2_Test': [r2_score(y_test, y_pred_test_best_rf)],\n",
    "    'MAE_Test': [mean_absolute_error(y_test, y_pred_test_best_rf)]\n",
    "}\n",
    "\n",
    "rf_results_df = pd.DataFrame(evaluation_metrics_xgb)\n",
    "\n",
    "# # Append results to the existing DataFrame\n",
    "# results_df = pd.concat([results_df, xgb_results_df], ignore_index=True)\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rf_results_df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf_results_df' is not defined"
     ]
    }
   ],
   "source": [
    "rf_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
